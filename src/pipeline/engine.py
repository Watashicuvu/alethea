# src/pipeline/engine.py
from qdrant_client.models import VectorParams, Distance
from src.config import PipelineOptions, config
from src.pipeline.context import PipelineContext
from src.pipeline.stages.ontology import OntologyLoader
from src.pipeline.stages.extraction import DocumentExtractor
from src.pipeline.stages.synthesis import WorldSynthesizer

class IngestionEngine:
    def __init__(self, options: PipelineOptions = PipelineOptions()):
        # 1. –ï–¥–∏–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        self.ctx = PipelineContext(options)
        
        # 2. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å—Ç–∞–¥–∏–π
        self.ontology_loader = OntologyLoader(self.ctx)
        self.extractor = DocumentExtractor(self.ctx)
        self.synthesizer = WorldSynthesizer(self.ctx)

    def setup_infrastructure(self):
        """
        –°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ Qdrant –∏ –∏–Ω–¥–µ–∫—Å—ã –≤ Neo4j –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º.
        """
        print("üõ†Ô∏è  Setting up DB Infrastructure...")
        
        # 1. Qdrant Dynamic Collections
        # (Static collection —Å–æ–∑–¥–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ OntologyLoader)
        dynamic_cols = [
            "molecules", "verbs", "vibes", 
            "chronicle", "narrative_instances",
            "skeleton_locations"
        ]
        
        for name in dynamic_cols:
            if not self.ctx.qdrant.collection_exists(name):
                self.ctx.qdrant.create_collection(
                    collection_name=name,
                    vectors_config=VectorParams(size=config.v_size, distance=Distance.COSINE),
                    shard_number=1
                )
                print(f"   + Qdrant Collection: {name}")

        # 2. Neo4j Constraints (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è —Å–∫—Ä—ã—Ç–æ –≤–Ω—É—Ç—Ä–∏ Neo4jClient.__init__)
        # –ù–æ –º–æ–∂–Ω–æ –¥–µ—Ä–Ω—É—Ç—å —è–≤–Ω–æ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å
        # self.ctx.neo4j_client._init_constraints()
        print("‚úÖ Infrastructure Ready.")

    def reset_context(self):
        self.ctx.reset_state()

    def index_registries(self, source_id: str = "core"):
        self.ontology_loader.run(source_id)

    def process_directory(self, input_dir: str, source_id: str):
        # –î–µ–ª–µ–≥–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—É —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä—É
        self.extractor.process_directory(input_dir, source_id)

    def run_post_processing(self, source_id: str):
        # –î–µ–ª–µ–≥–∏—Ä—É–µ–º —Ä–∞–±–æ—Ç—É —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä—É
        self.synthesizer.run(source_id)
