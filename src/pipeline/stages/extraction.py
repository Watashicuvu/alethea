import logging
from typing import List, Dict, Tuple, Optional
from llama_index.core import SimpleDirectoryReader, Document, PromptTemplate
from llama_index.core.schema import MetadataMode

from src.config import config
from src.pipeline.context import PipelineContext
from src.pipeline.stages.ingestion import BatchIngestor
from src.ingestion.scene_splitter import AdaptiveMicroSplitter
from src.ingestion.schemas import ExtractionBatch
from src.custom_program import LocalStructuredProgram as LLMTextCompletionProgram

class DocumentExtractor:
    """
    Stage 1: Text Processing & Extraction.
    –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞:
    1. –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤.
    2. Macro-Pass (–ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–∫–µ–ª–µ—Ç–∞ —á–µ—Ä–µ–∑ GraphBuilder).
    3. Micro-Pass (—É–º–Ω–∞—è –Ω–∞—Ä–µ–∑–∫–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π/—Å–≤—è–∑–µ–π).
    4. –ü–µ—Ä–µ–¥–∞—á—É –¥–∞–Ω–Ω—ã—Ö –≤ BatchIngestor.
    """

    def __init__(self, ctx: PipelineContext):
        self.ctx = ctx
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Å—å—é–º–µ—Ä–∞ (–æ–Ω –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ)
        self.ingestor = BatchIngestor(ctx)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—É –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        self._init_programs()

    def _init_programs(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ LLM –ø—Ä–æ–≥—Ä–∞–º–º—ã. 
        –ü—Ä–æ–º–ø—Ç –≤—ã–Ω–µ—Å–µ–Ω —Å—é–¥–∞, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ö–ª–∞–º–ª—è—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥.
        """
        prompt_templ = PromptTemplate(
            "Analyze the text chunk as a Game Engine Parser.\n"
            "Extract distinct entities and system interactions based on the following Ontology:\n\n"
            
            "1. MOLECULES (Entities):\n"
            "- AGENT: Beings with Will (Characters, Monsters).\n"
            "- GROUP: Factions or Squads.\n"
            "- ASSET: Objects. Distinguish between 'ARTIFACT' (Unique/Named) and 'COMMODITY' (Gold, Food, Ammo).\n"
            "- CONSTRUCT: Spells, Skills, or Phenomena. NOT verbs.\n"
            "- LORE: Information, secrets, codes.\n"
            "   - **CRITICAL**: The 'Description' MUST be a DIEGETIC FACT derived from THIS text chunk.\n"
            "   - If an entity is present but does nothing significant, SKIP IT.\n\n"
            
            "2. INTERACTIONS (Verbs & Actions):\n"
            "- EXTRACT significant actions.\n"
            "- IF it involves skill checks/combat/resources -> Label as MECHANIC.\n"
            "- IF it is purely narrative -> Label as FLAVOR.\n\n"
            
            "3. RELATIONSHIPS:\n"
            "- Connect entities logically (PHYSICAL, SOCIAL, MENTAL, LOGICAL).\n"
            "- Context Rules:\n"
            "   -- If context is 'MEMORY', prefer MENTAL links.\n"
            "   -- If context is 'PHYSICAL', use SPATIAL/LOCATED_AT links.\n\n"
            
            "TEXT CHUNK:\n{text_chunk}\n\n"
        )
        
        self.extractor_program = LLMTextCompletionProgram(
            output_cls=ExtractionBatch,
            llm=self.ctx.llm,
            prompt=prompt_templ, 
            verbose=True,
            # API –∫–ª—é—á–∏ —Ç–µ–ø–µ—Ä—å –±–µ—Ä—É—Ç—Å—è –∏–∑ LLM-–∫–ª–∏–µ–Ω—Ç–∞ –≤–Ω—É—Ç—Ä–∏ ctx, 
            # –Ω–æ –µ—Å–ª–∏ LocalStructuredProgram —Ç—Ä–µ–±—É–µ—Ç —è–≤–Ω–æ:
            api_key=config.llm.api_key,
            base_url=config.llm.base_url
        )

    def process_directory(self, input_dir: str, source_id: str):
        """
        –ì–ª–∞–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–∞–ø–∫–∏.
        """
        reader = SimpleDirectoryReader(input_dir)
        documents = reader.load_data()
        
        print(f"üöÄ Extractor: Found {len(documents)} documents in '{input_dir}' for source '{source_id}'.")

        for doc in documents:
            self._process_single_document(doc, source_id)

    def _process_single_document(self, doc: Document, source_id: str):
        source_ref = doc.doc_id
        print(f"\nüìÑ Processing Document: {source_ref}")

        # === PHASE 1: MACRO-PASS (SKELETON) ===
        # –î–µ–ª–µ–≥–∏—Ä—É–µ–º GraphBuilder'—É –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å—Ü–µ–Ω –∏ —Å–∫–µ–ª–µ—Ç–∞.
        # –¢–µ–ø–µ—Ä—å GraphBuilder –±–µ—Ä–µ—Ç—Å—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        scene_ranges, entity_registry = self.ctx.graph_builder.build_skeleton_v2(doc.text, source_ref, source_id)
        
        # === PHASE 2: MICRO-PASS (FLESH) ===
        self._process_micro_chunks(doc, source_ref, scene_ranges, entity_registry, source_id)

    def _process_micro_chunks(self, document: Document, source_ref: str, 
                              scene_ranges: List[tuple], 
                              entity_registry: Dict[str, str],
                              source_id: str):
        
        print(f"   üîç Micro-pass (Adaptive Semantic with Context Injection)...")
        
        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –°–ø–ª–∏—Ç—Ç–µ—Ä–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ—Å—É—Ä—Å—ã –∏–∑ Context)
        micro_parser = AdaptiveMicroSplitter(
            embedder=self.ctx.embedder,
            tokenizer=self.ctx.tokenizer, 
            min_tokens=500,
            max_tokens=2000,
            base_threshold=0.35
        )
        
        # 2. –ù–∞—Ä–µ–∑–∫–∞
        nodes = micro_parser.get_nodes_from_documents([document])
        
        for i, node in enumerate(nodes):
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            node_text = node.get_content(metadata_mode=MetadataMode.NONE)
            start_idx = node.metadata.get("start_char_idx", 0)
            end_idx = node.metadata.get("end_char_idx", len(node_text))
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            chunk_center = start_idx + (end_idx - start_idx) // 2
            
            # 3. Context Injection (–°–≤—è–∑—å Macro –∏ Micro)
            loc_id, context_data = self._find_location_for_offset(chunk_center, scene_ranges)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è LLM, —á—Ç–æ–±—ã –æ–Ω–∞ –ø–æ–Ω–∏–º–∞–ª–∞, –≥–¥–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –¥–µ–π—Å—Ç–≤–∏–µ
            context_prefix = ""
            if context_data:
                label = context_data.get('label', 'Unknown Context')
                sc_type = context_data.get('type', 'PHYSICAL')
                
                if sc_type != "PHYSICAL":
                    context_prefix = (
                        f"[SCENE TYPE: {sc_type} | CONTEXT: {label}]\n"
                        "NOTE: Entities here are likely MEMORIES or THOUGHTS.\n\n"
                    )
                else:
                    context_prefix = f"[SCENE: {label}]\n"
            
            final_chunk_text = context_prefix + node_text
            
            # 4. –í—ã–∑–æ–≤ LLM
            try:
                # –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —ç—Ç–æ Pydantic –æ–±—ä–µ–∫—Ç ExtractionBatch
                data: ExtractionBatch = self.extractor_program(text_chunk=final_chunk_text)
                
                # 5. HANDOFF -> INGESTION STAGE
                # –ú—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∏—á–µ–≥–æ –∑–¥–µ—Å—å. –ú—ã –ø–µ—Ä–µ–¥–∞–µ–º –¥–æ–±—ã—Ç—É—é —Ä—É–¥—É –Ω–∞ –∑–∞–≤–æ–¥ (Ingestor).
                self.ingestor.process(
                    batch=data,
                    source_ref=source_ref,
                    loc_id=loc_id,
                    entity_registry=entity_registry,
                    source_id=source_id,
                    current_tick=i
                )
                
            except Exception as e:
                logging.error(f"Error extracting from micro-chunk {i}: {e}", exc_info=True)

    def _find_location_for_offset(self, offset: int, ranges: List[tuple]) -> Tuple[Optional[str], Optional[dict]]:
        """
        –ò—â–µ—Ç, –≤ –∫–∞–∫–æ–π —Å—Ü–µ–Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è —Ç–æ—á–∫–∞ offset.
        ranges format: [(start, end, loc_uuid, context_data), ...]
        """
        for start, end, loc_uuid, context_data in ranges:
            if start <= offset < end:
                return loc_uuid, context_data
        return None, None
    