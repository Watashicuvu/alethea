# src/ingestion/mappers.py
from typing import Type, List, Dict, Optional
from enum import Enum
import numpy as np
from openai import OpenAI
from rapidfuzz import process, fuzz

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÐºÐ¾Ð½Ñ„Ð¸Ð³
from src.config import config

# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ‚Ð²Ð¾Ð¸ Enums 
from src.models.ecs.ontology_topology import EdgeType
from src.models.ecs.ontology_chronicle import CausalType
from src.models.ecs.ontology_edges import SocialRelType, ContainerRelType

class RelationshipSanitizer:
    """
    Ð¤Ð¸Ð»ÑŒÑ‚Ñ€, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€ÐµÑ‰Ð°ÐµÑ‚ Ñ„Ð¸Ð·Ð¸Ñ‡ÐµÑÐºÐ¸ Ð½ÐµÐ²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ñ‹Ðµ ÑÐ²ÑÐ·Ð¸
    Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ñ‚Ð¸Ð¿Ð¾Ð² ÑÑƒÑ‰Ð½Ð¾ÑÑ‚ÐµÐ¹ (Agent, Location, Asset).
    """
    
    @staticmethod
    def validate_and_fix(subj_type: str, obj_type: str, rel_type: str, rel_desc: str) -> str:
        s = subj_type.upper() if subj_type else "UNKNOWN"
        o = obj_type.upper() if obj_type else "UNKNOWN"
        r = rel_type.upper()
        
        # 1. Ð—ÐÐŸÐ Ð•Ð¢: ÐÐ³ÐµÐ½Ñ‚ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ ÐÐ³ÐµÐ½Ñ‚Ð°
        # "Alice LOCATED_AT King" -> "Alice NEAR King"
        if r in ["LOCATED_AT", "IS_INSIDE", "CONTAINED_BY"]:
            if s == "AGENT" and o == "AGENT":
                return "NEAR" # Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð½Ð° Ð¿Ñ€Ð¾ÑÑ‚Ñ€Ð°Ð½ÑÑ‚Ð²ÐµÐ½Ð½ÑƒÑŽ Ð±Ð»Ð¸Ð·Ð¾ÑÑ‚ÑŒ
            
            # ÐÐ³ÐµÐ½Ñ‚ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ ÐŸÑ€ÐµÐ´Ð¼ÐµÑ‚Ð° (ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ Ð½Ðµ Ð¢Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚)
            # ÐÐ»Ð¸ÑÐ° Ð² Ð‘ÑƒÑ‚Ñ‹Ð»ÐºÐµ? Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ (Ð¼Ð°Ð³Ð¸Ñ). ÐÐ»Ð¸ÑÐ° Ð² ÐœÐµÑ‡Ðµ? ÐÐµÑ‚.
            if s == "AGENT" and o == "ASSET":
                # Ð¢ÑƒÑ‚ Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÑ‚ÑŒ subtype Ð¿Ñ€ÐµÐ´Ð¼ÐµÑ‚Ð° (Container/Vehicle), Ð½Ð¾ Ð¿Ð¾ÐºÐ° Ð¾ÑÑ‚Ð°Ð²Ð¸Ð¼
                pass

        # 2. Ð—ÐÐŸÐ Ð•Ð¢: Ð›Ð¾ÐºÐ°Ñ†Ð¸Ñ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ñ‡ÐµÐ³Ð¾-Ð»Ð¸Ð±Ð¾ (ÐºÑ€Ð¾Ð¼Ðµ Ñ€ÐµÐ³Ð¸Ð¾Ð½Ð°)
        if s == "LOCATION" and r in ["LOCATED_AT"]:
            if o == "AGENT": 
                return "MENTIONED_BY" # Ð›ÐµÑ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð² ÐÐ»Ð¸ÑÐµ

        # 3. ÐœÐ•ÐÐ¢ÐÐ›Ð¬ÐÐ«Ð• ÐŸÐ ÐžÐ•ÐšÐ¦Ð˜Ð˜ (Ð ÐµÑˆÐµÐ½Ð¸Ðµ "Ð”Ð¾Ð´Ð¾ Ð½Ð° ÐÐ¸Ð»Ðµ")
        # Ð•ÑÐ»Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐ²ÑÐ·Ð¸ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ "thought", "remembered", "dreamt"
        keywords = ["thought", "remember", "dream", "imagine", "story"]
        if any(k in rel_desc.lower() for k in keywords):
            if r == "LOCATED_AT":
                return "THINKS_OF" # ÐžÑ‚Ð¼ÐµÐ½ÑÐµÐ¼ Ñ‚ÐµÐ»ÐµÐ¿Ð¾Ñ€Ñ‚Ð°Ñ†Ð¸ÑŽ

        return r

class EnumMapper:
    """
    Ð“Ð¸Ð±Ñ€Ð¸Ð´Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€: Hard Match -> Fuzzy Match -> OpenAILike Vector Match.
    """
    def __init__(self, enum_cls: Type[Enum], synonyms: Dict[str, List[str]]):
        print(f"ðŸ§  Initializing Hybrid Mapper for {enum_cls.__name__} via API...")
        self.enum_cls = enum_cls
        
        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° OpenAILike
        self.client = OpenAI(
            base_url=config.vector.base_url,
            api_key=config.vector.api_key
        )
        self.model_name = config.vector.model_name
        
        # 1. Hard/Fuzzy Map
        self.keyword_map = {}
        for enum_member in enum_cls:
            val = enum_member.value
            self.keyword_map[val.lower()] = val
            if val in synonyms:
                for syn in synonyms[val]:
                    self.keyword_map[syn.lower()] = val
        
        # 2. Vector Map (Soft Search)
        self.keys = [e.value for e in enum_cls]
        self.descriptions = []
        for e in enum_cls:
            # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð±Ð¾Ð³Ð°Ñ‚Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸
            desc = f"{e.value} {' '.join(synonyms.get(e.value, []))}"
            self.descriptions.append(desc)
            
        # ÐšÑÑˆÐ¸Ñ€ÑƒÐµÐ¼ Ð²ÐµÐºÑ‚Ð¾Ñ€Ñ‹ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹ Ð¿Ñ€Ð¸ ÑÑ‚Ð°Ñ€Ñ‚Ðµ
        self.vectors = self._get_embeddings_batch(self.descriptions)

    def _get_embeddings_batch(self, texts: List[str]) -> np.ndarray:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð±Ð°Ñ‚Ñ‡Ð° Ð²ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð²."""
        if not texts: return np.array([])
        resp = self.client.embeddings.create(input=texts, model=self.model_name)
        vecs = np.array([d.embedding for d in resp.data])
        # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
        norm = np.linalg.norm(vecs, axis=1, keepdims=True)
        return vecs / (norm + 1e-9)

    def _get_single_embedding(self, text: str) -> np.ndarray:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð°."""
        resp = self.client.embeddings.create(input=[text], model=self.model_name)
        vec = np.array(resp.data[0].embedding)
        norm = np.linalg.norm(vec)
        return vec / (norm + 1e-9)

    def classify(self, text: str, fuzzy_threshold: int = 85, vector_threshold: float = 0.35) -> Optional[str]:
        text_lower = text.lower()
        
        # --- STEP 1: KEYWORD SEARCH ---
        for kw, enum_val in self.keyword_map.items():
            if f" {kw} " in f" {text_lower} ": 
                return enum_val

        # --- STEP 2: FUZZY SEARCH ---
        best_match = process.extractOne(text_lower, self.keyword_map.keys(), scorer=fuzz.WRatio)
        if best_match:
            match_word, score, _ = best_match
            if score >= fuzzy_threshold:
                return self.keyword_map[match_word]

        # --- STEP 3: VECTOR SEARCH (OpenAILike API) ---
        query_vec = self._get_single_embedding(text) # (D,)
        
        # Dot product Ð´Ð»Ñ ÐºÐ¾ÑÐ¸Ð½ÑƒÑÐ½Ð¾Ð³Ð¾ ÑÑ…Ð¾Ð´ÑÑ‚Ð²Ð°
        scores = np.dot(self.vectors, query_vec)
        
        best_idx = int(np.argmax(scores))
        best_score = scores[best_idx]
        
        if best_score >= vector_threshold:
            return self.keys[best_idx]

        return None

# --- ÐšÐžÐÐ¤Ð˜Ð“Ð£Ð ÐÐ¦Ð˜Ð¯ Ð¡Ð˜ÐÐžÐÐ˜ÐœÐžÐ’ (Ð‘ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹) ---
SOCIAL_SYNONYMS = {
    "ally": ["friend", "partner", "supporter", "aiding", "loyal"],
    "hostile": ["enemy", "rival", "opponent", "hates", "attacking", "aggressor"],
    "neutral": ["stranger", "passerby", "ignoring", "unknown"],
    "master_of": ["leader", "boss", "commander", "owner", "domineering"],
    "parent_of": ["father", "mother", "creator", "ancestor"],
    "romantic": ["lover", "spouse", "wife", "husband", "intimate", "dating"]
}

CONTAINER_SYNONYMS = {
    "equipped_by": ["holding", "wielding", "wearing", "gripping", "brandishing"],
    "stored_by": ["in pocket", "in bag", "inventory", "carrying", "hidden in"],
    "located_at": ["standing in", "sitting on", "placed at", "lying on"],
    "implanted_in": ["inside body", "parasite", "chip", "cyberware"]
}

EDGE_SYNONYMS = {
    "path": ["road", "corridor", "hallway", "door", "walkway"],
    "secret": ["hidden passage", "concealed door", "crawlspace", "illusion"],
    "line_of_sight": ["window", "balcony", "overlooking", "visible from"],
    "portal": ["teleport", "gate", "rift", "wormhole"]
}

# --- FACADE ---
class RelationMapper:
    def __init__(self):
        # ÐŸÐµÑ€ÐµÐ´Ð°ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Enum Ð¸ Ð¡Ð¸Ð½Ð¾Ð½Ð¸Ð¼Ñ‹, ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ÑÑ Ð²Ð½ÑƒÑ‚Ñ€Ð¸ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ config
        self.social = EnumMapper(SocialRelType, SOCIAL_SYNONYMS)
        self.container = EnumMapper(ContainerRelType, CONTAINER_SYNONYMS)
        self.topology = EnumMapper(EdgeType, EDGE_SYNONYMS)
        self.causal = EnumMapper(CausalType, {}) 

    def map_social(self, text: str) -> str: return self.social.classify(text)
    def map_container(self, text: str) -> str: return self.container.classify(text)
    def map_edge(self, text: str) -> str: return self.topology.classify(text)
    def map_causal(self, text: str) -> str: return self.causal.classify(text)

RELATIONS = RelationMapper()
