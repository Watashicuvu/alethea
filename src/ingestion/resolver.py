from typing import Dict, Optional, List, Any
from rapidfuzz import fuzz, process
from pydantic import BaseModel, Field
from llama_index.core import PromptTemplate
from qdrant_client import models

from src.config import config
from src.custom_program import LocalStructuredProgram

class ResolutionResult(BaseModel):
    selected_id: Optional[str] = Field(description="The UUID of the entity that matches the query best. Return None if unsure.")
    reasoning: str = Field(description="Brief explanation (e.g. 'The text mentions her blonde hair, matching Alice').")

class EntityResolver:
    """
    –£–º–Ω—ã–π —Ä–µ–∑–æ–ª–≤–µ—Ä –∏–º–µ–Ω –≤ UUID.
    Pipeline: Cache -> Fuzzy -> Semantic (Qdrant) -> LLM (Context).
    """
    def __init__(self, ctx):
        self.ctx = ctx
        self._registry_cache: Dict[str, str] = {} # canonical_name -> uuid
        self._reverse_registry: Dict[str, str] = {} # uuid -> canonical_name (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ LLM)
        
        # === LLM PROGRAM ===
        self.llm_prompt = PromptTemplate(
            "You are a Contextual Entity Resolver.\n"
            "Identify who '{query}' refers to in the provided text snippet.\n\n"
            "CONTEXT TEXT:\n...{context}...\n\n"
            "CANDIDATES (Known Entities):\n"
            "{candidates_list}\n\n"
            "INSTRUCTIONS:\n"
            "1. Analyze the context to identify the specific individual.\n"
            "2. Match with the Candidates list.\n"
            "3. If '{query}' is a pronoun (She/He) or generic (The guard), use context clues.\n"
            "4. If no candidate matches or it's a new entity, return None.\n"
        )
        
        self.resolver_program = LocalStructuredProgram(
            output_cls=ResolutionResult,
            llm=self.ctx.llm,
            prompt=self.llm_prompt,
            verbose=True,
            api_key=config.llm.api_key,
            base_url=config.llm.base_url
        )

    def load_registry(self, registry: Dict[str, str]):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–µ—Å—Ç—Ä –∏–º–µ–Ω –∏–∑ Pass 2."""
        self._registry_cache = {k.lower(): v for k, v in registry.items()}
        # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        self._reverse_registry = {v: k for k, v in registry.items()}

    def resolve_name(self, name_query: str, context_loc_id: Optional[str] = None) -> Optional[str]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è.
        """
        clean_name = name_query.lower().strip()
        if len(clean_name) < 2: return None

        # 1. EXACT & PARTIAL MATCH (In Memory)
        # –°–∞–º—ã–π –±—ã—Å—Ç—Ä—ã–π —ç—Ç–∞–ø. –ò—â–µ–º –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ä–µ–µ—Å—Ç—Ä–µ —Ç–µ–∫—É—â–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
        if clean_name in self._registry_cache:
            return self._registry_cache[clean_name]

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ ("Hatter" in "The Mad Hatter")
        # process.extractOne –≤–µ—Ä–Ω–µ—Ç –ª—É—á—à–∏–π –º–∞—Ç—á
        best_match = process.extractOne(
            clean_name, 
            self._registry_cache.keys(), 
            scorer=fuzz.ratio,
            score_cutoff=85
        )
        if best_match:
            match_name, score, _ = best_match
            return self._registry_cache[match_name]

        # 2. CONTEXTUAL SEARCH (In Location)
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –ø–∞–º—è—Ç–∏, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ "–°—Ç—Ä–∞–∂–Ω–∏–∫", –∏ –Ω–∞–º –Ω—É–∂–µ–Ω –∏–º–µ–Ω–Ω–æ "–°—Ç—Ä–∞–∂–Ω–∏–∫ –≤ —ç—Ç–æ–π –ª–æ–∫–∞—Ü–∏–∏".
        if context_loc_id:
            loc_specific_id = self.ctx.repos.entities.find_entity_in_location(
                context_loc_id, clean_name
            )
            if loc_specific_id:
                return loc_specific_id

        # 3. GLOBAL FUZZY SEARCH (Database)
        # –ò—â–µ–º –ø–æ –≤—Å–µ–π –±–∞–∑–µ Neo4j (–¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö NPC, –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω—ã—Ö –≤ –¥—Ä—É–≥–∏—Ö –∫–Ω–∏–≥–∞—Ö)
        global_id = self.ctx.repos.entities.fuzzy_search_molecule(clean_name, threshold=0.85)
        if global_id:
            return global_id
            
        return None

    def resolve(self, name_query: str, context_text: str, scene_cast_uids: List[str] = []) -> Optional[str]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥.
        Args:
            name_query: –ò–º—è/–§—Ä–∞–∑–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ ("The girl", "She", "Excalibur")
            context_text: –¢–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ (–ø–∞—Ä–∞–≥—Ä–∞—Ñ –∏–ª–∏ —Å—Ü–µ–Ω–∞)
            scene_cast_uids: –°–ø–∏—Å–æ–∫ UUID —Ç–µ—Ö, –∫—Ç–æ —Ç–æ—á–Ω–æ –µ—Å—Ç—å –≤ —Å—Ü–µ–Ω–µ (–¥–ª—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞)
        """
        clean_name = name_query.lower().strip()
        if len(clean_name) < 2: return None
        if clean_name in ["someone", "anyone", "no one"]: return None

        # 1. FAST LOOKUP (Registry)
        if clean_name in self._registry_cache:
            return self._registry_cache[clean_name]

        # 2. FUZZY MATCH (Registry)
        # –ò—â–µ–º —Å—Ä–µ–¥–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏–º–µ–Ω
        best_match = process.extractOne(
            clean_name, 
            self._registry_cache.keys(), 
            scorer=fuzz.ratio,
            score_cutoff=85
        )
        if best_match:
            match_name, score, _ = best_match
            print(f"   ‚ö° Fuzzy Resolved: '{name_query}' -> {match_name}")
            return self._registry_cache[match_name]

        # 3. SEMANTIC SEARCH (Qdrant)
        # "The golden blade" -> "Excalibur"
        # –ò—â–µ–º –ø–æ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –º–æ–ª–µ–∫—É–ª (—É –Ω–∞—Å —Ç–∞–º –µ—Å—Ç—å —á–µ—Ä–Ω–æ–≤–∏–∫–∏ –∏–∑ Pass 2)
        sem_id = self._semantic_search(name_query)
        if sem_id:
            print(f"   üß† Semantic Resolved: '{name_query}' -> {sem_id}")
            return sem_id

        # 4. LLM CONTEXTUAL RESOLUTION (Fallback)
        # –ï—Å–ª–∏ —ç—Ç–æ –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ –∏–ª–∏ —Å–ª–æ–∂–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ ("The one who knocked")
        # –ò–õ–ò –µ—Å–ª–∏ Fuzzy/Semantic –Ω–µ –¥–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –Ω–æ –∏–º—è –≤—ã–≥–ª—è–¥–∏—Ç –≤–∞–∂–Ω—ã–º
        if len(context_text) > 10:
            return self._resolve_with_llm(name_query, context_text, scene_cast_uids)

        return None

    def _semantic_search(self, query: str) -> Optional[str]:
        """–ü–æ–∏—Å–∫ –ø–æ —Å–º—ã—Å–ª—É –≤ Qdrant (molecules)."""
        if not self.ctx.qdrant.collection_exists("molecules"):
            return None
            
        vec = self.ctx.embedder.get_text_embedding(query)
        
        # –ò—â–µ–º Top-1
        res = self.ctx.qdrant.query_points(
            collection_name="molecules",
            query=vec,
            limit=1
        )
        
        # –ü–æ—Ä–æ–≥ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤—ã—Å–æ–∫–∏–º, —á—Ç–æ–±—ã –Ω–µ —Ü–µ–ø–ª—è—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—â–∏
        if res.points and res.points[0].score > 0.88:
            return res.points[0].id
        return None

    def _resolve_with_llm(self, query: str, context: str, priority_uids: List[str]) -> Optional[str]:
        """
        –°–ø—Ä–∞—à–∏–≤–∞–µ–º LLM, –∫—Ç–æ —ç—Ç–æ.
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ—Ç–¥–∞–µ–º entity –∏–∑ scene_cast (—Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤).
        """
        # 1. –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ (–∫—Ç–æ –≤ —Å—Ü–µ–Ω–µ), –ø–æ—Ç–æ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ (–µ—Å–ª–∏ –º–∞–ª–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö)
        candidates_desc = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º Cast
        for uid in priority_uids:
            name = self._reverse_registry.get(uid, "Unknown")
            # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å –≤ metadata —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä–∞
            desc = self._get_entity_desc(uid)
            candidates_desc.append(f"- {name} (ID: {uid}): {desc}")
        
        # –ï—Å–ª–∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã—Ö –º–∞–ª–æ, –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ä–µ–µ—Å—Ç—Ä–∞ (–¥–æ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤)
        if len(candidates_desc) < 5:
            for name, uid in list(self._registry_cache.items())[:10]: # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
                if uid not in priority_uids:
                     candidates_desc.append(f"- {name} (ID: {uid})")

        candidates_str = "\n".join(candidates_desc)
        
        # 2. –í—ã–∑—ã–≤–∞–µ–º LLM
        try:
            # –û–±—Ä–µ–∑–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ (–≤–æ–∫—Ä—É–≥ —Å–æ–±—ã—Ç–∏—è)
            safe_context = context[-2000:] if len(context) > 2000 else context
            
            res = self.resolver_program(
                query=query,
                context=safe_context,
                candidates_list=candidates_str
            )
            
            if res.selected_id and res.selected_id.lower() != "none":
                print(f"      ü§ñ LLM Resolved: '{query}' -> {res.selected_id} ({res.reasoning})")
                return res.selected_id
                
        except Exception as e:
            # logging.error(f"LLM Resolution failed: {e}")
            pass
            
        return None

    def _get_entity_desc(self, uid: str) -> str:
        """–•–µ–ª–ø–µ—Ä: –¥–æ—Å—Ç–∞–µ—Ç category/subtype –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä–∞."""
        if hasattr(self.ctx, 'synthesizer'):
            meta = self.ctx.synthesizer._metadata.get(uid, {})
            return f"{meta.get('category', 'Entity')} {meta.get('subtype', '')}"
        return "Entity"
    